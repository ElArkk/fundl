{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fundl.layers.rnn import gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "       [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "       [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       "       [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       "       [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
       "       [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy.random as npr\n",
    "import jax.numpy as np\n",
    "\n",
    "x = np.arange(0, 100).reshape(10, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ericmjl/anaconda/envs/fundl-dev/lib/python3.7/site-packages/jax/lib/xla_bridge.py:114: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "from fundl.weights import add_gru_params\n",
    "\n",
    "params = dict()\n",
    "params = add_gru_params(params, \"gru\", 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 3.83266062e-01, -0.00000000e+00],\n",
       "             [ 3.85106236e-01, -0.00000000e+00],\n",
       "             [ 3.16568166e-01, -0.00000000e+00],\n",
       "             [-1.19605124e-01, -0.00000000e+00],\n",
       "             [-1.69583106e+00, -0.00000000e+00],\n",
       "             [-7.06654167e+00, -0.00000000e+00],\n",
       "             [-2.64628792e+01, -0.00000000e+00],\n",
       "             [-1.03442741e+02, -0.00000000e+00],\n",
       "             [-4.42269745e+02, -0.00000000e+00],\n",
       "             [-2.10259766e+03, -0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru(params[\"gru\"], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.lax import batch_matmul\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feats = defaultdict(list)\n",
    "adjacency_matrices = defaultdict(list)\n",
    "for i in range(1000):\n",
    "    num_nodes = npr.randint(3, 20)\n",
    "    node_feat = npr.normal(size=(num_nodes, 10))\n",
    "    amat = npr.binomial(n=1, p=0.3, size=(num_nodes, num_nodes)).astype(float)\n",
    "    \n",
    "    node_feats[num_nodes].append(node_feat)\n",
    "    adjacency_matrices[num_nodes].append(amat)\n",
    "    # node_feats.append(node_feat)\n",
    "    # adjacency_matrices.append(amat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data batched by graph size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feats_batched = dict()\n",
    "adj_mats_batched = dict()\n",
    "for k, v in node_feats.items():\n",
    "    node_feats_batched[k] = np.stack(v)\n",
    "    adj_mats_batched[k] = np.stack(adjacency_matrices[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def message_passing(feats, adjs):\n",
    "    outputs = dict()\n",
    "    for k in feats.keys():\n",
    "        outputs[k] = batch_matmul(adjs[k], feats[k])\n",
    "    return outputs\n",
    "\n",
    "output = message_passing(node_feats_batched, adj_mats_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 19, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[19].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56, 13, 10), (56, 13, 13))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = 13\n",
    "node_feats_batched[num_nodes].shape, adj_mats_batched[num_nodes].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data padded with zeros to largest graph size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_graph_size = 20\n",
    "\n",
    "for size, feats in node_feats.items():\n",
    "    pad_size = largest_graph_size - size\n",
    "    node_feats[size] = np.pad(\n",
    "        feats, \n",
    "        pad_width=(\n",
    "            # syntax is n_before, n_after\n",
    "            (0, 0),  # sample dimension, do not touch\n",
    "            (0, pad_size),  # node dimension, pad to largest size\n",
    "            (0, 0),  # feats simension, do not touch\n",
    "        )\n",
    "    )\n",
    "    \n",
    "for size, adj in adjacency_matrices.items():\n",
    "    pad_size = largest_graph_size - size\n",
    "    adjacency_matrices[size] = np.pad(\n",
    "        adj,\n",
    "        pad_width=[\n",
    "            # syntax is n_before, n_after\n",
    "            (0, 0),  # sample dimension, do not touch\n",
    "            (0, pad_size),  # node dimension, pad to largest size\n",
    "            (0, pad_size),  # node dimension, pad to largest size\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 20, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feats[16].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, stack them along the same axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feats_stacked = []\n",
    "for size, feats in node_feats.items():\n",
    "    node_feats_stacked.append(feats)\n",
    "node_feats_stacked = np.concatenate(node_feats_stacked, axis=0)\n",
    "\n",
    "adj_mats_stacked = []\n",
    "for size, adj in adjacency_matrices.items():\n",
    "    adj_mats_stacked.append(adj)\n",
    "adj_mats_stacked = np.concatenate(adj_mats_stacked, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp1 = batch_matmul(adj_mats_stacked, node_feats_stacked)\n",
    "summation = np.sum(mp1, axis=1)\n",
    "summation.shape  # n_samples by n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mbatch_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mbatch_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\"Batch matrix multiplication.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0m_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Arguments to batch_matmul must be at least 2D, got {}, {}'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Arguments to batch_matmul must have same ndim, got {}, {}'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mlhs_contract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mrhs_contract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mdot_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlhs_contract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs_contract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda/envs/fundl-dev/lib/python3.7/site-packages/jax/lax/lax.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_matmul??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Equivalence\n",
    "\n",
    "Make sure that message passing with padding is equivalent to message passing without padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.array([[1, 0], [1, 1]])\n",
    "A = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "M = np.dot(A, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[1, 0],\n",
       "             [1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[1, 0, 0, 0],\n",
       "             [0, 1, 0, 0],\n",
       "             [0, 0, 0, 0],\n",
       "             [0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_size = 2\n",
    "F_pad = np.pad(\n",
    "    F, \n",
    "    pad_width=[\n",
    "        (0, pad_size),\n",
    "        (0, 0),\n",
    "    ]\n",
    ")\n",
    "F_pad\n",
    "\n",
    "A_pad = np.pad(\n",
    "    A,\n",
    "    pad_width=[\n",
    "        (0, pad_size),\n",
    "        (0, pad_size),\n",
    "    ]\n",
    ")\n",
    "\n",
    "A_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[1, 0, 0, 0],\n",
       "             [0, 1, 0, 0],\n",
       "             [0, 0, 0, 0],\n",
       "             [0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_pad = np.dot(A_pad, F_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[1, 0],\n",
       "             [1, 1],\n",
       "             [0, 0],\n",
       "             [0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE ARE THE TESTS OF EQUIVALENCE!\n",
    "assert np.all(np.pad(M, [(0, pad_size), (0, 0)]) == M_pad)\n",
    "assert np.all(M_pad[:-pad_size, :] == M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundl-dev",
   "language": "python",
   "name": "fundl-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
